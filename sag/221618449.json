{"id":221618449,"name":"Iterative temporal learning and prediction with the sparse online echo state gaussian process","abstraction":"In this paper we propose a new basis selection criterion for building sparse GP regression models that provides promising gains in accuracy as well as efficiency over previous methods. Our algorithm is much faster than that of Smola and Bartlett, while, in generalization it greatly outper- forms the information gain approach proposed by Seeger et al, especially on the quality of predictive distributions.","authors":["S. Sathiya Keerthi"],"citedInUrls":["https://www.researchgate.net/publication/261523828_Iterative_temporal_learning_and_prediction_with_the_sparse_online_echo_state_gaussian_process","https://www.researchgate.net/publication/43247171_Sparse_Approximation_Through_Boosting_for_Learning_Large_Scale_Kernel_Machines","https://www.researchgate.net/publication/221618015_Variational_Mixture_of_Gaussian_Process_Experts"],"refrenceUrls":["https://www.researchgate.net/publication/49459301_Fast_Forward_Selection_to_Speed_Up_Sparse_Gaussian_Process_Regression","https://www.researchgate.net/publication/49459305_Using_the_Nystroem_Method_to_Speed_Up_Kernel_Machines","https://www.researchgate.net/publication/2893638_Bayesian_Gaussian_Process_Models_PAC-Bayesian_Generalisation_Error_Bounds_and_Sparse_Approximations","https://www.researchgate.net/publication/226966322_Kernel_Matching_Pursuit","https://www.researchgate.net/publication/2538204_Sparse_Greedy_Gaussian_Process_Regression","https://www.researchgate.net/publication/3698260_Comparison_of_basis_selection_methods","https://www.researchgate.net/publication/242388870_Learning_with_Uncertainty_Gaussian_Processes_and_Relevance_Vector_Machines"],"citedInIDs":[261523828,43247171,221618015],"refrenceIDs":[49459301,49459305,2893638,226966322,2538204,3698260,242388870],"pageRank":9.372190597292732E-4}
