{"id":220270203,"name":"Strategies and Principles of Distributed Machine Learning on Big Data","abstraction":"We define a probability distribution over equivalence classes of binary ma- trices with a finite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features. We derive the distribution by taking the limit of a distribution over N Ã— K binary matrices as K ! 1, a strategy inspired by the derivation of the Chinese restaurant process (Aldous, 1985; Pitman, 2002) as the limit of a Dirichlet-multinomial model. This strategy preserves the exchangeability of the rows of matrices. We define several simple generative processes that result in the same distri- bution over equivalence classes of binary matrices, one of which we call the Indian buffet process. We illustrate the use of this distribution as a prior in an infinite latent feature model, deriving a Markov chain Monte Carlo algo- rithm for inference in this model and applying this algorithm to an artificial dataset.","authors":["Tom Griffiths","Zoubin Ghahramani"],"citedInUrls":["https://www.researchgate.net/publication/288889800_Strategies_and_Principles_of_Distributed_Machine_Learning_on_Big_Data","https://www.researchgate.net/publication/283433373_Streaming_Distributed_Variational_Inference_for_Bayesian_Nonparametrics","https://www.researchgate.net/publication/283279776_Scaled_subordinators_and_generalizations_of_the_Indian_buffet_process"],"refrenceUrls":["https://www.researchgate.net/publication/229100346_Markov_Chain_Sampling_Methods_for_Dirichlet_Process_Mixture_Models","https://www.researchgate.net/publication/229100417_A_Constructive_Definition_of_the_Dirichlet_Prior","https://www.researchgate.net/publication/27290603_Gibbs_Sampling_Methods_for_Stick_-_breaking_Priors","https://www.researchgate.net/publication/2741222_Bayesian_Density_Estimation_and_Inference_Using_Mixtures","https://www.researchgate.net/publication/2641493_Developing_Population_Codes_By_Minimizing_Description_Length","https://www.researchgate.net/publication/245581848_Bayesian_density_estimation_by_mixtures_of_normal_distributions_Recent_Adv_Stat","https://www.researchgate.net/publication/2251788_Hierarchical_Priors_and_Mixture_Models_With_Application_in_Regression_and_Density_Estimation","https://www.researchgate.net/publication/221618091_Parametric_Mixture_Models_for_Multi-Labeled_Text","https://www.researchgate.net/publication/243662369_A_semiparametric_Bayesian_model_for_randomised_block_designs","https://www.researchgate.net/publication/221996674_The_Infinite_Gaussian_Mixture_Model"],"citedInIDs":[288889800,283433373,283279776],"refrenceIDs":[229100346,229100417,27290603,2741222,2641493,245581848,2251788,221618091,243662369,221996674],"pageRank":0.0020107106976870286}
