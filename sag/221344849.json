{"id":221344849,"name":"Classification in the Presence of Label Noise: A Survey","abstraction":"One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated hypothesis usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon,is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example,is simply the difference between,the number,of correct votes and the maximum,number,of votes received by any incorrect label. We show that techniques used in the analysis of Vapnikâ€™s support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those","authors":["Robert E. Schapire","Peter Barlett","Wee Sun Lee"],"citedInUrls":["https://www.researchgate.net/publication/261601383_Classification_in_the_Presence_of_Label_Noise_A_Survey","https://www.researchgate.net/publication/259137349_Multiobjective_genetic_classifier_selection_for_random_oracles_fuzzy_rule-based_classifier_ensembles_How_beneficial_is_the_additional_diversity","https://www.researchgate.net/publication/252016839_Theoretical_and_empirical_analysis_of_diversity_in_non-stationary_learning"],"refrenceUrls":["https://www.researchgate.net/publication/221620492_Boosting_Decision_Trees","https://www.researchgate.net/publication/226270700_Bagging_Predictors","https://www.researchgate.net/publication/2780927_Rates_of_Convex_Approximation_in_Non-Hilbert_Spaces","https://www.researchgate.net/publication/2671722_Error-Correcting_Output_Coding_Corrects_Bias_and_Variance","https://www.researchgate.net/publication/220343893_Kohavi_R_An_Empirical_Comparison_of_Voting_Classification_Algorithms_Bagging_Boosting_and_Variants_Machine_Learning_361-2_105-139","https://www.researchgate.net/publication/3501836_The_Strength_of_Weak_Learnability","https://www.researchgate.net/publication/2262068_An_Empirical_Evaluation_of_Bagging_and_Boosting","https://www.researchgate.net/publication/260303138_Structural_risk_minimization_over_data-dependent_hierarchies_IEEE_Trans_Inf_Theory","https://www.researchgate.net/publication/228582526_Training_methods_for_adaptive_boosting_of_neural_networks_for_character_recognition","https://www.researchgate.net/publication/2424244_Improving_Regressors_Using_Boosting_Techniques"],"citedInIDs":[261601383,259137349,252016839],"refrenceIDs":[221620492,226270700,2780927,2671722,220343893,3501836,2262068,260303138,228582526,2424244],"pageRank":0.0013432783828647161}
