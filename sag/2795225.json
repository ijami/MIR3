{"id":2795225,"name":"Pseudo-Marginal Bayesian Inference for Gaussian Processes","abstraction":"Gaussian processes are a promising non-linear interpolation tool (Williams 1995; Williams and Rasmussen 1996), but it is not straightforward to solve classification problems with them. In this paper the variational methods of Jaakkola and Jordan (1996) are applied to Gaussian processes to produce an efficient Bayesian binary classifier. 1 Introduction Assume that we have some data D which consists of inputs fx n g N n\u003d1 in some space, real or discrete, and corresponding targets t n which are binary categorical variables. We shall model this data using a Bayesian conditional classifier which predicts t conditional on x. We assume the existence of a function a(x) which models the `logit\u0027 log P (t\u003d1jx) P (t\u003d0jx) as a function of x. Thus P (t \u003d 1jx; a(x)) \u003d 1 1 + exp(Gammaa(x)) (1) To complete the model we place a prior distribution over the unknown function a(x). There are two approaches to this. In the standard parametric approach, a(x) is a parameterized function a(x; w) where the...","authors":["Mark N. Gibbs"],"citedInUrls":["https://www.researchgate.net/publication/262954130_Pseudo-Marginal_Bayesian_Inference_for_Gaussian_Processes","https://www.researchgate.net/publication/258849788_On_Approximate_Inference_for_Generalized_Gaussian_Process_Models","https://www.researchgate.net/publication/257299295_Exact-Approximate_Bayesian_Inference_for_Gaussian_Processes"],"refrenceUrls":[],"citedInIDs":[262954130,258849788,257299295],"refrenceIDs":[],"pageRank":6.577422487543643E-4}
