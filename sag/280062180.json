{"id":280062180,"name":"Improved graph-based SFA: Information preservation complements the slowness principle","abstraction":"Nonnegative Matrix Factorization (NMF) aims to factorize a matrix into two optimized nonnegative matrices appropriate for the intended applications. The method has been widely used for unsupervised learning tasks, including recommender systems (rating matrix of users by items) and document clustering (weighting matrix of papers by keywords). However, traditional NMF methods typically assume the number of latent factors (i.e., dimensionality of the loading matrices) to be fixed. This assumption makes them inflexible for many applications. In this paper, we propose a nonparametric NMF framework to mitigate this issue by using dependent Indian Buffet Processes (dIBP). In a nutshell, we apply a correlation function for the generation of two stick weights associated with each pair of columns of loading matrices, while still maintaining their respective marginal distribution specified by IBP. As a consequence, the generation of two loading matrices will be column-wise (indirectly) correlated. Under this same framework, two classes of correlation function are proposed (1) using Bivariate beta distribution and (2) using Copula function. Both methods allow us to adopt our work for various applications by flexibly choosing an appropriate parameter settings. Compared with the other state-of-the art approaches in this area, such as using Gaussian Process (GP)-based dIBP, our work is seen to be much more flexible in terms of allowing the two corresponding binary matrix columns to have greater variations in their non-zero entries. Our experiments on the real-world and synthetic datasets show that three proposed models perform well on the document clustering task comparing standard NMF without predefining the dimension for the factor matrices, and the Bivariate beta distribution-based and Copula-based models have better flexibility than the GP-based model.","authors":["Jie Lu","Guangquan Zhang","Richard Yi Da Xu","Xiangfeng Luo"],"citedInUrls":[],"refrenceUrls":["https://www.researchgate.net/publication/51759504_Symmetric_Nonnegative_Matrix_Factorization_Algorithms_and_Applications_to_Probabilistic_Clustering","https://www.researchgate.net/publication/27535444_Sparse_Nonnegative_Matrix_Factorization_for_Clustering","https://www.researchgate.net/publication/229100346_Markov_Chain_Sampling_Methods_for_Dirichlet_Process_Mixture_Models","https://www.researchgate.net/publication/220270203_Infinite_Latent_Feature_Models_and_the_Indian_Buffet_Process","https://www.researchgate.net/publication/51927792_A_Tutorial_on_Bayesian_Nonparametric_Models","https://www.researchgate.net/publication/220320786_Stick-breaking_Construction_for_the_Indian_Buffet_Process","https://www.researchgate.net/publication/221345374_Bayesian_Nonparametric_Matrix_Factorization_for_Recorded_Music","https://www.researchgate.net/publication/220320618_Nonparametric_Bayesian_Matrix_Factorization_by_Power-EP","https://www.researchgate.net/publication/226423227_The_Phylogenetic_Indian_Buffet_Process_A_Non-Exchangeable_NonparametricPrior_for_Latent_Features","https://www.researchgate.net/publication/222077028_A_bivariate_beta_distribution"],"citedInIDs":[],"refrenceIDs":[51759504,27535444,229100346,220270203,51927792,220320786,221345374,220320618,226423227,222077028],"pageRank":5.314734299140724E-4}
