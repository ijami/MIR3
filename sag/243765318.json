{"id":243765318,"name":"Fast Bayesian Lasso for High-Dimensional Regression","abstraction":"We study the covariance structure of a Markov chain generated by the Gibbs sampler, with emphasis on data augmentation. When applied to a Bayesian missing data problem, the Gibbs sampler produces two natural approximations for the posterior distribution of the parameter vector: the empirical distribution based on the sampled values of the parameter vector, and a mixture of complete data posteriors. We prove that Rao-Blackwellization causes a one-lag delay for the autocovariances among dependent samples obtained from data augmentation, and consequently, the mixture approximation produces estimates with smaller variances than the empirical approximation. The covariance structure results are used to compare different augmentation schemes. It is shown that collapsing and grouping random components in a Gibbs sampler with two or three components usually result in more efficient sampling schemes.","authors":["Wing Hung Wong","Augustine Kong"],"citedInUrls":["https://www.researchgate.net/publication/281808410_Fast_Bayesian_Lasso_for_High-Dimensional_Regression","https://www.researchgate.net/publication/263736976_A_Bayesian_Method_of_Change-point_Estimation_with_Recurrent_Regimes_Application_to_GARCH_Models","https://www.researchgate.net/publication/228878888_Regulatory_Motif_Discovery_from_Decoding_to_Meta-Analysis"],"refrenceUrls":[],"citedInIDs":[281808410,263736976,228878888],"refrenceIDs":[],"pageRank":9.626289560090725E-4}
