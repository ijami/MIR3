{"id":3079570,"name":"Learning without Concentration for General Loss Functions","abstraction":"We show that if the closure of a function class F under the metric induced by some probability distribution is not convex, then the sample complexity for agnostically learning F with squared loss (using only hypotheses in F) is Ω(ln(1/δ)/ε2) where 1-δ is the probability of success and ε is the required accuracy. In comparison, if the class F is convex and has finite pseudodimension, then the sample complexity is O(1/ε(ln(1/ε)+ln(1/b)). If a nonconvex class F has finite pseudodimension, then the sample complexity for agnostically learning the closure of the convex hull of F, is O(1/ε(1/ε(ln(1/ε)+ln(1/δ)). Hence, for agnostic learning, learning the convex hull provides better approximation capabilities with little sample complexity penalty","authors":["Robert C. Williamson"],"citedInUrls":["https://www.researchgate.net/publication/266856478_Learning_without_Concentration_for_General_Loss_Functions","https://www.researchgate.net/publication/263281433_The_Sample_Complexity_of_Learning_Linear_Predictors_with_the_Squared_Loss","https://www.researchgate.net/publication/235432144_Passive_Learning_with_Target_Risk"],"refrenceUrls":["https://www.researchgate.net/publication/222190436_Decision_Theoretic_Generalizations_of_the_PAC_Model_for_Neural_Net_and_Other_Learning_Applications","https://www.researchgate.net/publication/220570748_Bounding_Sample_Size_with_the_Vapnik-Chervonenkis_Dimension","https://www.researchgate.net/publication/220360940_Convergence_rates_for_single_hidden_layer_feedforward_networks","https://www.researchgate.net/publication/2261777_Uniform_Ratio_Limit_Theorems_for_Empirical_Processes","https://www.researchgate.net/publication/222505227_A_generalization_of_Sauer%27s_lemma","https://www.researchgate.net/publication/223075780_Learning_Distributions_by_Their_Density_Levels_A_Paradigm_for_Learning_without_a_Teacher","https://www.researchgate.net/publication/3079179_Efficient_agnostic_learning_of_neural_networks_with_bounded_fan-in","https://www.researchgate.net/publication/230663954_Weak_Convergence_and_Empirical_Process","https://www.researchgate.net/publication/3505541_Efficient_Distribution-free_Learning_of_Probabilistic_Concepts","https://www.researchgate.net/publication/225304623_Inroduction_to_Statistical_Pattern_Recognition"],"citedInIDs":[266856478,263281433,235432144],"refrenceIDs":[222190436,220570748,220360940,2261777,222505227,223075780,3079179,230663954,3505541,225304623],"pageRank":0.001699713551575421}
