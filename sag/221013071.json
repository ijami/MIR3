{"id":221013071,"name":"Latent-Descriptor Clustering for Unsupervised POS Induction","abstraction":"There is growing interest in applying Bayesian techniques to NLP problems. There are a number of different estimators for Bayesian models, and it is useful to know what kinds of tasks each does well on. This paper compares a variety of different Bayesian estimators for Hidden Markov Model POS taggers with var- ious numbers of hidden states on data sets of different sizes. Recent papers have given con- tradictory results when comparing Bayesian estimators to Expectation Maximization (EM) for unsupervised HMM POS tagging, and we show that the difference in reported results is largely due to differences in the size of the training data and the number of states in the HMM. We invesigate a variety of samplers for HMMs, including some that these earlier pa- pers did not study. We find that all of Gibbs samplers do well with small data sets and few states, and that Variational Bayes does well on large data sets and is competitive with the Gibbs samplers. In terms of times of conver- gence, we find that Variational Bayes was the fastest of all the estimators, especially on large data sets, and that explicit Gibbs sampler (both pointwise and sentence-blocked) were gener- ally faster than their collapsed counterparts on large data sets.","authors":["Jianfeng Gao","Mark Johnson"],"citedInUrls":["https://www.researchgate.net/publication/221012731_Latent-Descriptor_Clustering_for_Unsupervised_POS_Induction","https://www.researchgate.net/publication/221012878_Two_Decades_of_Unsupervised_POS_induction_How_far_have_we_come","https://www.researchgate.net/publication/221101448_A_comparison_of_unsupervised_methods_for_Part-of-Speech_Tagging_in_Chinese"],"refrenceUrls":["https://www.researchgate.net/publication/34000771_Variational_algorithms_for_approximate_Bayesian_inference","https://www.researchgate.net/publication/220816756_Prototype-Driven_Learning_for_Sequence_Models","https://www.researchgate.net/publication/220947031_Combining_Distributional_and_Morphological_Information_for_Part_of_Speech_Induction","https://www.researchgate.net/publication/226763007_Comparing_Clusterings_by_the_Variation_of_Information","https://www.researchgate.net/publication/220874388_A_fully_Bayesian_approach_to_unsupervised_part-of-speech_tagging","https://www.researchgate.net/publication/3084564_Pattern_recognition_and_machine_learning","https://www.researchgate.net/publication/220695762_InformationTheory_Inference_and_Learning_Algorithms","https://www.researchgate.net/publication/220182914_Geman_D_Stochastic_relaxation_Gibbs_distribution_and_the_Bayesian_restoration_of_images_IEEE_Trans_Pattern_Anal_Mach_Intell_PAMI-66_721-741","https://www.researchgate.net/publication/220817030_Bayesian_Inference_for_PCFGs_via_Markov_Chain_Monte_Carlo","https://www.researchgate.net/publication/251408299_An_Introduction_to_Markov_Chain_Monte_Carlo_Methods"],"citedInIDs":[221012731,221012878,221101448],"refrenceIDs":[34000771,220816756,220947031,226763007,220874388,3084564,220695762,220182914,220817030,251408299],"pageRank":0.001040575178656416}
