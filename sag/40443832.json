{"id":40443832,"name":"DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks","abstraction":"While many models of biological object recognition share a common set of \"broad-stroke\" properties, the performance of any one model depends strongly on the choice of parameters in a particular instantiation of that model--e.g., the number of units per layer, the size of pooling kernels, exponents in normalization operations, etc. Since the number of such parameters (explicit or implicit) is typically large and the computational cost of evaluating one particular parameter set is high, the space of possible model instantiations goes largely unexplored. Thus, when a model fails to approach the abilities of biological visual systems, we are left uncertain whether this failure is because we are missing a fundamental idea or because the correct \"parts\" have not been tuned correctly, assembled at sufficient scale, or provided with enough training. Here, we present a high-throughput approach to the exploration of such parameter sets, leveraging recent advances in stream processing hardware (high-end NVIDIA graphic cards and the PlayStation 3\u0027s IBM Cell Processor). In analogy to high-throughput screening approaches in molecular biology and genetics, we explored thousands of potential network architectures and parameter instantiations, screening those that show promising object recognition performance for further analysis. We show that this approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature. As the scale of available computational power continues to expand, we argue that this approach has the potential to greatly accelerate progress in both artificial vision and our understanding of the computational underpinning of biological vision.","authors":[],"citedInUrls":["https://www.researchgate.net/publication/289587844_DrMAD_Distilling_Reverse-Mode_Automatic_Differentiation_for_Optimizing_Hyperparameters_of_Deep_Neural_Networks","https://www.researchgate.net/publication/275669188_Deep_Neural_Networks_with_Random_Gaussian_Weights_A_Universal_Classification_Strategy","https://www.researchgate.net/publication/266676858_Deep_Representations_for_Iris_Face_and_Fingerprint_Spoofing_Attack_Detection"],"refrenceUrls":["https://www.researchgate.net/publication/15829465_Fukushima_K_Neocognitron_A_self-organizing_neural_network_model_for_a_mechanism_of_pattern_recognition_unaffected_by_shift_in_position_Biol_Cybern_36_193-202","https://www.researchgate.net/publication/12774907_Riesenhuber_M_Poggio_T_Hierarchical_models_of_object_recognition_in_cortex_Nat_Neurosci_2_1019-1025","https://www.researchgate.net/publication/220659858_Object_Class_Recognition_and_Localization_Using_Sparse_Features_with_Limited_Receptive_Fields","https://www.researchgate.net/publication/5625818_Why_is_Real-World_Visual_Object_Recognition_Hard","https://www.researchgate.net/publication/221363188_How_far_can_you_get_with_a_modern_face_recognition_test_set_using_only_simple_features","https://www.researchgate.net/publication/2985293_Cramming_More_Components_Onto_Integrated_Circuits","https://www.researchgate.net/publication/221174163_Scientific_Computing_on_Commodity_Graphics_Hardware","https://www.researchgate.net/publication/215991433_Learning_Invariance_From_Transformation_Sequences","https://www.researchgate.net/publication/23252305_Unsupervised_Natural_Experience_Rapidly_Alters_Invariant_Object_Representation_in_Visual_Cortex","https://www.researchgate.net/publication/3216496_NVIDIA_tesla_a_unified_graphics_and_computing_architecture_IEEE_Micro"],"citedInIDs":[289587844,275669188,266676858],"refrenceIDs":[15829465,12774907,220659858,5625818,221363188,2985293,221174163,215991433,23252305,3216496],"pageRank":7.02642496429573E-4}
