{"id":220344042,"name":"Compatible Value Gradients for Reinforcement Learning of Continuous Deep Policies","abstraction":"Technical process control is a highly interesting area of application serving a high practical impact. Since classical controller design is, in general, a demanding job, this area constitutes a highly attractive domain for the application of learning approachesâ€”in particular, reinforcement learning (RL) methods. RL provides concepts for learning controllers that, by cleverly exploiting information from interactions with the process, can acquire high-quality control behaviour from scratch. This article focuses on the presentation of four typical benchmark problems whilst highlighting important and challenging aspects of technical process control: nonlinear dynamics; varying set-points; long-term dynamic effects; influence of external variables; and the primacy of precision. We propose performance measures for controller quality that apply both to classical control design and learning controllers, measuring precision, speed, and stability of the controller. A second set of key-figures describes the performance from the perspective of a learning approach while providing information about the efficiency of the method with respect to the learning effort needed. For all four benchmark problems, extensive and detailed information is provided with which to carry out the evaluations outlined in this article. A close evaluation of our own RL learning scheme, NFQCA (Neural Fitted Q Iteration with Continuous Actions), in acordance with the proposed scheme on all four benchmarks, thereby provides performance figures on both control quality and learning behavior.","authors":["Roland Hafner"],"citedInUrls":["https://www.researchgate.net/publication/281632506_Compatible_Value_Gradients_for_Reinforcement_Learning_of_Continuous_Deep_Policies","https://www.researchgate.net/publication/265479118_Batch_Reinforcement_Learning","https://www.researchgate.net/publication/228120927_Reinforcement_Learning_and_Optimal_Adaptive_Control_An_Overview_and_Implementation_Examples_vol_36_pg_42_2012"],"refrenceUrls":["https://www.researchgate.net/publication/222005258_Modeling_and_robust_control_of_Blu-ray_disc_servo-mechanisms","https://www.researchgate.net/publication/4249967_Evaluation_of_Policy_Gradient_Methods_and_Variants_on_the_Cart-Pole_Benchmark","https://www.researchgate.net/publication/3568712_A_Direct_Adaptive_Method_for_Faster_Backpropagation_Learning_The_RPROP_Algorithm","https://www.researchgate.net/publication/51406980_Adaptive_Critic_Learning_Techniques_for_Engine_Torque_and_Air-Fuel_Ratio_Control","https://www.researchgate.net/publication/229713662_Adaptive_robust_nonlinear_control_of_a_magnetic_levitation_system_via_DSC_technique","https://www.researchgate.net/publication/220806883_Springer_Tracts_in_Advanced_Robotics","https://www.researchgate.net/publication/43605370_Policy_Gradient_Based_Reinforcement_Learning_for_Real_Autonomous_Underwater_Cable_Tracking","https://www.researchgate.net/publication/268260202_ADAPTIVE_REACTIVE_JOB-SHOP_SCHEDULING_WITH_REINFORCEMENT_LEARNING_AGENTS","https://www.researchgate.net/publication/3352099_Nonlinear_autopilot_control_design_for_a_2-DOF_helicopter_model","https://www.researchgate.net/publication/243683810_Dynamic_nonlinear_modeling_of_a_hot-water-to-air_heat_exchanger_for_control_applications"],"citedInIDs":[281632506,265479118,228120927],"refrenceIDs":[222005258,4249967,3568712,51406980,229713662,220806883,43605370,268260202,3352099,243683810],"pageRank":6.165596775082664E-4}
