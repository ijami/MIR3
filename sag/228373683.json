{"id":228373683,"name":"Social Network Aware Device-to-Device Communication in Wireless Networks","abstraction":"We describe a flexible nonparametric approach to latent variable modelling in which the number of latent variables is unbounded. This approach is based on a probability distribution over equivalence classes of binary matrices with a finite number of rows, corresponding to the data points, and an unbounded number of columns, corresponding to the latent variables. Each data point can be associated with a subset of the possible latent variables, which we re-fer to as the latent features of that data point. The binary variables in the matrix indicate which latent feature is possessed by which data point, and there is a potentially infinite array of features. We derive the distribution over unbounded binary matrices by taking the limit of a distribution over N × K binary matrices as K → ∞. We define a simple generative processes for this distribution which we call the Indian buffet process (IBP; Griffiths and Ghahramani, 2005, 2006) by analogy to the Chinese restaurant process (Aldous, 1985; Pitman, 2002). The IBP has a single hyperparameter which controls both the number of feature per object and the total number of fea-tures. We describe a two-parameter generalization of the IBP which has addi-tional flexibility, independently controlling the number of features per object and the total number of features in the matrix. The use of this distribution as a prior in an infinite latent feature model is illustrated, and Markov chain Monte Carlo algorithms for inference are described.","authors":["Zoubin Ghahramani","Thomas L Griffiths"],"citedInUrls":["https://www.researchgate.net/publication/273398187_Social_Network_Aware_Device-to-Device_Communication_in_Wireless_Networks","https://www.researchgate.net/publication/268226636_Bayesian_group_latent_factor_analysis_with_structured_sparse_priors","https://www.researchgate.net/publication/258657494_On_Confidence-Constrained_Rank_Recovery_in_Topic_Models"],"refrenceUrls":["https://www.researchgate.net/publication/220270203_Infinite_Latent_Feature_Models_and_the_Indian_Buffet_Process","https://www.researchgate.net/publication/229100346_Markov_Chain_Sampling_Methods_for_Dirichlet_Process_Mixture_Models","https://www.researchgate.net/publication/42790702_A_Modified_Principal_Component_Technique_Based_on_the_LASSO","https://www.researchgate.net/publication/229100978_Bayesian_Auxiliary_Variable_Models_for_Binary_and_Multinomial_Regression","https://www.researchgate.net/publication/2741222_Bayesian_Density_Estimation_and_Inference_Using_Mixtures","https://www.researchgate.net/publication/221346403_A_choice_model_with_infinitely_many_latent_features","https://www.researchgate.net/publication/228851557_Bayesian_model_assessment_in_factor_analysis","https://www.researchgate.net/publication/23951944_Sparse_Principal_Components_Analysis","https://www.researchgate.net/publication/228092026_A_Non-Parametric_Bayesian_Method_for_Inferring_Hidden_Causes","https://www.researchgate.net/publication/12752937_Learning_the_Parts_of_Objects_by_Non-Negative_Matrix_Factorization"],"citedInIDs":[273398187,268226636,258657494],"refrenceIDs":[220270203,229100346,42790702,229100978,2741222,221346403,228851557,23951944,228092026,12752937],"pageRank":5.827972458743409E-4}
