{"id":264936662,"name":"A Bayesian approach to constrained single- and multi-objective optimization","abstraction":"We consider the problem of maximizing a real-valued continuous function $f$ using a Bayesian approach. Since the early work of Jonas Mockus and Antanas \\v{Z}ilinskas in the 70\u0027s, the problem of optimization is usually formulated by considering the loss function $\\max f - M_n$ (where $M_n$ denotes the best function value observed after $n$ evaluations of $f$). This loss function puts emphasis on the value of the maximum, at the expense of the location of the maximizer. In the special case of a one-step Bayes-optimal strategy, it leads to the classical Expected Improvement (EI) sampling criterion. This is a special case of a Stepwise Uncertainty Reduction (SUR) strategy, where the risk associated to a certain uncertainty measure (here, the expected loss) on the quantity of interest is minimized at each step of the algorithm. In this article, assuming that $f$ is defined over a measure space $(\\mathbb{X}, \\lambda)$, we propose to consider instead the integral loss function $\\int_{\\mathbb{X}} (f - M_n)_{+}\\, d\\lambda$, and we show that this leads, in the case of a Gaussian process prior, to a new numerically tractable sampling criterion that we call $\\rm EI^2$ (for Expected Integrated Expected Improvement). A numerical experiment illustrates that a SUR strategy based on this new sampling criterion reduces the error on both the value and the location of the maximizer faster than the EI-based strategy.","authors":["Emmanuel Vazquez","Julien Bect"],"citedInUrls":["https://www.researchgate.net/publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization"],"refrenceUrls":["https://www.researchgate.net/publication/46587486_Sequential_design_of_computer_experiments_for_the_estimation_of_aprobability_of_failure","https://www.researchgate.net/publication/228438518_Fast_Parallel_Kriging-Based_Stepwise_Uncertainty_Reduction_With_Application_to_the_Identification_of_an_Excursion_Set","https://www.researchgate.net/publication/258831560_Fast_Computation_of_the_Multi-Points_Expected_Improvement_with_Applications_in_Batch_Selection","https://www.researchgate.net/publication/235709802_Efficient_Global_Optimization_of_Expensive_Black-Box_Functions","https://www.researchgate.net/publication/242922491_Bayesian_Approach_to_Global_Optimization--Theory_and_Applications","https://www.researchgate.net/publication/248818761_The_application_of_Bayesian_methods_for_seeking_the_extremum","https://www.researchgate.net/publication/257299288_Multiobjective_optimization_using_Gaussian_process_emulators_via_stepwise_uncertainty_reduction","https://www.researchgate.net/publication/1960302_An_informational_approach_to_the_global_optimization_of_expensive-to-evaluate_functions"],"citedInIDs":[282570552],"refrenceIDs":[46587486,228438518,258831560,235709802,242922491,248818761,257299288,1960302],"pageRank":5.314734299140724E-4}
