{"id":278244488,"name":"Bridging the Gap between Stochastic Gradient MCMC and Stochastic Optimization","abstraction":"A new framework for topic modeling is developed , based on deep graphical models, where interactions between topics are inferred through deep latent binary hierarchies. The proposed multi-layer model employs a deep sigmoid belief network or restricted Boltzmann machine, the bottom binary layer of which selects topics for use in a Poisson factor analysis model. Under this setting, topics live on the bottom layer of the model, while the deep specification serves as a flexible prior for revealing topic structure. Scal-able inference algorithms are derived by applying Bayesian conditional density filtering algorithm, in addition to extending recently proposed work on stochastic gradient thermostats. Experimental results on several corpora show that the proposed approach readily handles very large collections of text documents, infers structured topic representations , and obtains superior test perplexities when compared with related models.","authors":["Changyou Chen","Lawrence Carin"],"citedInUrls":["https://www.researchgate.net/publication/288713780_Bridging_the_Gap_between_Stochastic_Gradient_MCMC_and_Stochastic_Optimization","https://www.researchgate.net/publication/288059688_High-Order_Stochastic_Gradient_Thermostats_for_Bayesian_Learning_of_Deep_Models","https://www.researchgate.net/publication/278413644_Learning_Deep_Generative_Models_with_Doubly_Stochastic_MCMC"],"refrenceUrls":["https://www.researchgate.net/publication/227375782_Riemann_manifold_Langevin_and_Hamiltonian_Monte_Carlo_methods","https://www.researchgate.net/publication/259743415_Bayesian_Conditional_Density_Filtering_for_Big_Data","https://www.researchgate.net/publication/11207765_ARTICLE_Training_Products_of_Experts_by_Minimizing_Contrastive_Divergence"],"citedInIDs":[288713780,288059688,278413644],"refrenceIDs":[227375782,259743415,11207765],"pageRank":6.395194586051127E-4}
