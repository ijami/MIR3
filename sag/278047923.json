{"id":278047923,"name":"Uncertainty quantification in coronary blood flow simulations: impact of geometry, boundary conditions and blood viscosity","abstraction":"Decision forests and their variants deliver efficient state-of-the-art prediction performance, but many applications, such as probabilistic numerics, Bayesian optimization, uncertainty quantification, and planning, also demand a measure of the uncertainty associated with each prediction. Existing approaches to measuring the uncertainty of decision forest predictions are known to perform poorly, and so Gaussian processes and approximate variants are the standard tools in these application areas. With a goal of providing efficient state-of-the-art predictions together with estimates of uncertainty, we describe a regression framework using Mondrian forests, an approach to decision forests where the underlying random decision trees are modeled as i.i.d. Mondrian processes and efficient algorithms perform nonparametric Bayesian inference within each tree and ordinary model combination across trees. In our framework, the underlying nonparametric inference is a Gaussian diffusion over the tree, which results in a multivariate Gaussian calculation for inference in light of finite data that can be carried out efficiently using belief propagation. On a synthetic task designed to mimic a typical probabilistic numerical task, we demonstrate that Mondrian forest regression delivers far superior uncertainty quantification than existing decision forest methods with little-to-no cost in predictive performance. We then turn to a real-world probabilistic numerics benchmark modeling flight delay, where we compare Mondrian forests also to large-scale GP approximate methods. Our experiments demonstrate that Mondrian forests can deliver superior uncertainty assessments to GPs, as measured by negative predictive log density, with little-to-no loss in RMSE performance.","authors":["Balaji Lakshminarayanan","Daniel M. Roy","Yee Whye Teh"],"citedInUrls":[],"refrenceUrls":["https://www.researchgate.net/publication/48166394_A_Tutorial_on_Bayesian_Optimization_of_Expensive_Cost_Functions_with_Application_to_Active_User_Modeling_and_Hierarchical_Reinforcement_Learning","https://www.researchgate.net/publication/215990477_An_Empirical_Comparison_of_Supervised_Learning_Algorithms","https://www.researchgate.net/publication/272194844_Distributed_Gaussian_Processes","https://www.researchgate.net/publication/260089482_Distributed_Variational_Inference_in_Sparse_Gaussian_Process_Regression_and_Latent_Variable_Models","https://www.researchgate.net/publication/220343368_Extremely_Randomized_Trees","https://www.researchgate.net/publication/257069490_Gaussian_Processes_for_Big_Data","https://www.researchgate.net/publication/216300820_Automated_Configuration_of_Algorithms_for_Solving_Hard_Computational_Problems","https://www.researchgate.net/publication/273388016_Kernel-Based_Just-In-Time_Learning_for_Passing_Expectation_Propagation_Messages","https://www.researchgate.net/publication/263012120_Mondrian_Forests_Efficient_Online_Random_Forests","https://www.researchgate.net/publication/248818761_The_application_of_Bayesian_methods_for_seeking_the_extremum"],"citedInIDs":[],"refrenceIDs":[48166394,215990477,272194844,260089482,220343368,257069490,216300820,273388016,263012120,248818761],"pageRank":5.314734299140724E-4}
